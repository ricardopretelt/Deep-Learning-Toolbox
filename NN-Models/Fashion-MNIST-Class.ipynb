{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"Fashion-MNIST-Class.ipynb","provenance":[{"file_id":"1lsxvCua1lt4Gla0xUR7IW4FR4FA8wa4J","timestamp":1571617998233}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"zcXCCjs_Wmvi","colab_type":"text"},"source":["# Fashion-MNIST-Class\n","In this case a NN is built using pytorch to define a class for the architecture but not using the functional module. It is the most general way to define a model."]},{"cell_type":"markdown","metadata":{"id":"CYweTsL9Wmvm","colab_type":"text"},"source":["### Importing the libraries and loading the data"]},{"cell_type":"code","metadata":{"id":"0mWjUNK9Wmvo","colab_type":"code","colab":{}},"source":["# Importing libraries\n","import torch\n","from torch import nn\n","from torch import optim\n","from torchvision import datasets, transforms\n","import helper\n","# Define a transform to normalize the data\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))])\n","# Download and load the training data\n","trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","# Download and load the test data\n","testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LAr-Rql5lalX","colab_type":"code","outputId":"9026ce2a-78b4-457e-d0dd-3992be86d5ce","executionInfo":{"status":"ok","timestamp":1571620781340,"user_tz":300,"elapsed":1375,"user":{"displayName":"Ricardo Pretelt","photoUrl":"https://lh6.googleusercontent.com/-A-eRxY0THTQ/AAAAAAAAAAI/AAAAAAAACD0/OVNEOkFTFKY/s64/photo.jpg","userId":"15013903332028054215"}},"colab":{"base_uri":"https://localhost:8080/","height":267}},"source":["#Viewing the images\n","image, label = next(iter(trainloader))\n","helper.imshow(image[0,:])"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f29c1d534a8>"]},"metadata":{"tags":[]},"execution_count":25},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAdMAAAHTCAYAAAB8/vKtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5yPlmKoAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"image/png":{"width":233,"height":233}}}]},{"cell_type":"markdown","metadata":{"id":"MYCPcrX9Wmvv","colab_type":"text"},"source":["### Defining the architecture of the network "]},{"cell_type":"code","metadata":{"id":"vJaXBg8-Wmvw","colab_type":"code","colab":{}},"source":["class Classifier(nn.Module):\n","    def __init__(self):\n","        super().__init__()        \n","        # Inputs to hidden layer linear transformation\n","        self.hidden1 = nn.Linear(784, 256)\n","        self.hidden2 = nn.Linear(256, 128)\n","        self.hidden3 = nn.Linear(128, 64)\n","        # Output layer, 10 units - one for each digit\n","        self.output = nn.Linear(64, 10)        \n","        # Define sigmoid activation and softmax output \n","        self.sigmoid = nn.Sigmoid()\n","        self.softmax = nn.Softmax(dim=1)        \n","    def forward(self, x):\n","        # Pass the input tensor through each of our operations\n","        x = self.hidden1(x)\n","        x = self.hidden2(x)\n","        x = self.hidden3(x)\n","        x = self.output(x)\n","        #x = self.sigmoid(x)\n","        x = self.softmax(x)        \n","        return x\n","# Define the loss and optimizer\n","model = Classifier()\n","criterion = nn.NLLLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.003)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S8K9tE7FWmv-","colab_type":"text"},"source":["### Train the network"]},{"cell_type":"code","metadata":{"id":"QnmvpyIXWmv_","colab_type":"code","outputId":"e3908807-da4e-4729-bc2c-add7f5214f1b","executionInfo":{"status":"ok","timestamp":1571620923533,"user_tz":300,"elapsed":143514,"user":{"displayName":"Ricardo Pretelt","photoUrl":"https://lh6.googleusercontent.com/-A-eRxY0THTQ/AAAAAAAAAAI/AAAAAAAACD0/OVNEOkFTFKY/s64/photo.jpg","userId":"15013903332028054215"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["epochs = 5\n","for e in range(epochs):\n","    running_loss = 0\n","    for images, labels in trainloader:\n","        # Flatten MNIST images into a 784 long vector\n","        images = images.view(images.shape[0], -1)\n","        # Training\n","        images, labels = next(iter(trainloader))\n","        images.resize_(64, 784)\n","        # Clear the gradients, do this because gradients are accumulated\n","        optimizer.zero_grad()\n","        # Forward pass, then backward pass, then update weights\n","        output = model.forward(images)\n","        loss = criterion(output, labels)\n","        loss.backward()        \n","        # Take an update step and few the new weights\n","        optimizer.step()        \n","        running_loss += loss.item()\n","    else:\n","        print(f\"Training loss: {running_loss/len(trainloader)}\")"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Training loss: -0.10733602214247179\n","Training loss: -0.15794237313081205\n","Training loss: -0.28171773046763465\n","Training loss: -0.3685402595030982\n","Training loss: -0.45687260794868345\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jmecgbpeWmwJ","colab_type":"text"},"source":["### Forward test data to calculate accuracy"]},{"cell_type":"code","metadata":{"id":"NIuS-_qCWmwK","colab_type":"code","outputId":"4bee75a6-8ce7-4736-cf17-f417e5bc3dc9","executionInfo":{"status":"ok","timestamp":1571620923539,"user_tz":300,"elapsed":143496,"user":{"displayName":"Ricardo Pretelt","photoUrl":"https://lh6.googleusercontent.com/-A-eRxY0THTQ/AAAAAAAAAAI/AAAAAAAACD0/OVNEOkFTFKY/s64/photo.jpg","userId":"15013903332028054215"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Forward pass with 1 batch of images from the test dataset\n","images, labels = next(iter(testloader))\n","images.resize_(64, 784)\n","# Turn off gradients to speed up this part\n","with torch.no_grad():\n","    ps1 = model(images)\n","# Get the class probabilities\n","ps = torch.exp(ps1)\n","# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n","print(ps.shape)\n","\n","\n","\n","#Forward pass with 1 batch of images from the test dataset\n","#images, labels = next(iter(testloader))\n","#images.resize_(64, 784)\n","# Get the class probabilities\n","#ps = torch.exp(model(images))\n","# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n","#print(ps.shape)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["torch.Size([64, 10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b6UpBBe6WmwQ","colab_type":"code","outputId":"2b3bb09d-deee-4e11-85b8-83c6fd5b6e65","executionInfo":{"status":"ok","timestamp":1571620923540,"user_tz":300,"elapsed":143480,"user":{"displayName":"Ricardo Pretelt","photoUrl":"https://lh6.googleusercontent.com/-A-eRxY0THTQ/AAAAAAAAAAI/AAAAAAAACD0/OVNEOkFTFKY/s64/photo.jpg","userId":"15013903332028054215"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["#To obtain the class with the highest probability using method ps.topk\n","top_p, top_class = ps.topk(1, dim=1)\n","# Look at the most likely classes for the first 10 examples\n","print(top_class[:10,:])"],"execution_count":29,"outputs":[{"output_type":"stream","text":["tensor([[4],\n","        [8],\n","        [9],\n","        [4],\n","        [1],\n","        [4],\n","        [1],\n","        [1],\n","        [8],\n","        [7]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HOQe_eJpWmwV","colab_type":"code","colab":{}},"source":["# Now we want to check that the class obtained in the probabilities with the model correspond to the labels\n","# It can be done equationg top_class=labels but we need to be sure that they are the same shape.\n","# Equals must have the size (64,64)\n","equals = top_class == labels.view(*top_class.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w29viiBnWmwa","colab_type":"code","outputId":"f1ae9a7d-2dd3-4774-fc53-41c3485e2fc7","executionInfo":{"status":"ok","timestamp":1571620923543,"user_tz":300,"elapsed":143444,"user":{"displayName":"Ricardo Pretelt","photoUrl":"https://lh6.googleusercontent.com/-A-eRxY0THTQ/AAAAAAAAAAI/AAAAAAAACD0/OVNEOkFTFKY/s64/photo.jpg","userId":"15013903332028054215"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#To get the accuracy. \n","#Equals is in the form of 0s and 1s, so the total sum divided by the total size of items gives the accuracy.\n","#Accuracy is a mean of how much the model got right\n","accuracy = torch.mean(equals.type(torch.FloatTensor))\n","print(f'Accuracy: {accuracy.item()*100}%')"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Accuracy: 48.4375%\n"],"name":"stdout"}]}]}